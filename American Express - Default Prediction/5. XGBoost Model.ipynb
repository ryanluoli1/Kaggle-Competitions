{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train XGBoost with GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "GPU = True\n",
    "try:\n",
    "    import cupy, cudf\n",
    "except ImportError:\n",
    "    GPU = False\n",
    "\n",
    "cudf = pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VER = 1\n",
    "FEATURE_VER = 111\n",
    "\n",
    "SEED = 108+5*VER+100*FEATURE_VER\n",
    "\n",
    "FOLDS = 5\n",
    "\n",
    "FEATURE_PATH = './'\n",
    "\n",
    "DO_SUBMIT = False\n",
    "\n",
    "print(\"VER:\", VER)\n",
    "print(\"fVER:\", FEATURE_VER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering: https://www.kaggle.com/code/roberthatch/amex-feature-engg-gpu-or-cpu-process-in-chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_miss_nan(df):\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    for c in df.columns:\n",
    "        if c in get_not_used(): continue\n",
    "        if str( df[c].dtype )=='int64':\n",
    "            df[c] = df[c].astype('int32')\n",
    "        if str(df[c].dtype )=='float64':\n",
    "            df[c] = df[c].astype('float32')\n",
    "    return df\n",
    "\n",
    "def get_not_used():  \n",
    "    return ['row_id', 'customer_ID', 'target', 'cid', 'S_2','D_103','D_139']    \n",
    "\n",
    "train = do_miss_nan(train)\n",
    "test = do_miss_nan(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Reading train data...')\n",
    "TRAIN_PATH = f'{FEATURE_PATH}train_fe_v1.pickle'\n",
    "train = pd.read_pickle(TRAIN_PATH)\n",
    "print(train.shape)\n",
    "train = do_miss_nan(train)\n",
    "train = train.sample(frac=1, random_state=SEED)\n",
    "train = train.reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train using `DeviceQuantileDMatrix` which has a very small GPU memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "print('XGB Version',xgb.__version__)\n",
    "\n",
    "BASE_LEARNING_RATE = 0.01\n",
    "\n",
    "xgb_params = { \n",
    "    'max_depth': 7,\n",
    "    'subsample':0.75,\n",
    "    'colsample_bytree': 0.35,\n",
    "    'gamma':1.5,\n",
    "    'lambda':70,\n",
    "    'min_child_weight':8,\n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':['logloss', 'auc'],  ## Early stopping is based on the last metric listed.\n",
    "    'tree_method':'gpu_hist',\n",
    "    'predictor':'gpu_predictor',\n",
    "    'random_state':SEED,\n",
    "    'num_parallel_tree':1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterLoadForDMatrix(xgb.core.DataIter):\n",
    "    \n",
    "    def __init__(self, df=None, features=None, target=None, batch_size=256*1024):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.df = df\n",
    "        self.it = 0 # set iterator to 0\n",
    "        self.batch_size = batch_size\n",
    "        self.batches = int( np.ceil( len(df) / self.batch_size ) )\n",
    "        super().__init__()\n",
    "\n",
    "    def reset(self):\n",
    "        '''Reset the iterator'''\n",
    "        self.it = 0\n",
    "\n",
    "    def next(self, input_data):\n",
    "        '''Yield next batch of data.'''\n",
    "        if self.it == self.batches:\n",
    "            return 0 \n",
    "        a = self.it * self.batch_size\n",
    "        b = min( (self.it + 1) * self.batch_size, len(self.df) )\n",
    "        dt = cudf.DataFrame(self.df.iloc[a:b])\n",
    "        input_data(data=dt[self.features], label=dt[self.target]) #, weight=dt['weight'])\n",
    "        self.it += 1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amex_metric_mod(y_true, y_pred):\n",
    "    labels     = np.transpose(np.array([y_true, y_pred]))\n",
    "    labels     = labels[labels[:, 1].argsort()[::-1]]\n",
    "    weights    = np.where(labels[:,0]==0, 20, 1)\n",
    "    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n",
    "    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n",
    "    gini = [0,0]\n",
    "    for i in [1,0]:\n",
    "        labels         = np.transpose(np.array([y_true, y_pred]))\n",
    "        labels         = labels[labels[:, i].argsort()[::-1]]\n",
    "        weight         = np.where(labels[:,0]==0, 20, 1)\n",
    "        weight_random  = np.cumsum(weight / np.sum(weight))\n",
    "        total_pos      = np.sum(labels[:, 0] *  weight)\n",
    "        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n",
    "        lorentz        = cum_pos_found / total_pos\n",
    "        gini[i]        = np.sum((lorentz - weight_random) * weight)\n",
    "    print(\"  4%  :\", top_four)\n",
    "    print(\"  Gini:\", gini[1]/gini[0])\n",
    "    print(\"Kaggle:\", 0.5 * (gini[1]/gini[0] + top_four))\n",
    "    return 0.5 * (gini[1]/gini[0] + top_four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = []\n",
    "PYRAMID_W = [0.5, 2/3, 0.75, 0.875, 1, 0]\n",
    "\n",
    "def run_training(train, features):\n",
    "    oof = []\n",
    "    skf = KFold(n_splits=FOLDS)\n",
    "    for fold,(train_idx, valid_idx) in enumerate(skf.split(\n",
    "                train, train.target )):\n",
    "        print('#'*25)\n",
    "        print('### Fold',fold+1)\n",
    "        X_train = train.loc[train_idx, features]\n",
    "        y_train = train.loc[train_idx, 'target']\n",
    "        X_valid = train.loc[valid_idx, features]\n",
    "        y_valid = train.loc[valid_idx, 'target']\n",
    "        print('### Train size',len(train_idx),'Valid size',len(valid_idx),'Valid positives',y_valid.sum())\n",
    "        print(f'### Training with all of fold data...')\n",
    "        print('#'*25)\n",
    "        dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(data=X_valid, label=y_valid)\n",
    "        pyramid_layers = [(100,  10,  1.56,  0.5),\n",
    "                          ( 20,  50,  1.3,   2/3),\n",
    "                          (  1,1000,  1.25,  0.75),\n",
    "                          (  1,1000,  1.125, 0.875),\n",
    "                          (  1,3000,  1.0,   1),\n",
    "                          (  1,9000,  0.5,   0)]\n",
    "        assert(PYRAMID_W == [layer[-1] for layer in pyramid_layers])\n",
    "        for (layer, (n_trees, n_rounds, adj_learning, w)) in enumerate(pyramid_layers):\n",
    "            xgb_params['num_parallel_tree'] = n_trees\n",
    "            xgb_params['learning_rate'] = n_trees*adj_learning*BASE_LEARNING_RATE\n",
    "            xgb_params['random_state'] += 1\n",
    "            early_stop = None\n",
    "            if w == 0:\n",
    "                early_stop = 300\n",
    "            print(\"Learning Rate:\", xgb_params['learning_rate'])\n",
    "            model = xgb.train(xgb_params, \n",
    "                        dtrain=dtrain,\n",
    "                        evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "                        num_boost_round=n_rounds,\n",
    "                        early_stopping_rounds=early_stop,\n",
    "                        verbose_eval=100//n_trees)\n",
    "            model.save_model(f'XGB_v{VER}_fold{fold}_layer{layer}.xgb')\n",
    "            if (w != 0):\n",
    "                ptrain = model.predict(dtrain, output_margin=True)\n",
    "                pvalid = model.predict(dvalid, output_margin=True)\n",
    "                if (w < 1.0):\n",
    "                    ptrain = ptrain * w\n",
    "                    pvalid = pvalid * w\n",
    "                dtrain.set_base_margin(ptrain)\n",
    "                dvalid.set_base_margin(pvalid)\n",
    "                plt.hist(pvalid, bins=100)\n",
    "                plt.title(f'Layer {layer} OOF Predictions')\n",
    "                plt.show()\n",
    "                del model, ptrain, pvalid\n",
    "                gc.collect()\n",
    "        dd = model.get_score(importance_type='weight')\n",
    "        df = pd.DataFrame({'feature':dd.keys(),f'importance_{fold}':dd.values()})\n",
    "        importances.append(df)\n",
    "        print(\"Best_ntree_limit:\", model.best_ntree_limit//xgb_params['num_parallel_tree'])\n",
    "        oof_preds = model.predict(dvalid, iteration_range=(0,model.best_ntree_limit//xgb_params['num_parallel_tree']))\n",
    "        print('For this fold:')\n",
    "        amex_metric_mod(y_valid.values, oof_preds)\n",
    "        df = train.loc[valid_idx, ['customer_ID','target'] ].copy()\n",
    "        df['oof_pred'] = oof_preds\n",
    "        oof.append( df )\n",
    "        del X_train, y_train, dd, df\n",
    "        del X_valid, y_valid, dvalid, model\n",
    "        gc.collect()\n",
    "    print('#'*25)\n",
    "    print('OVERALL CV:')\n",
    "    oof = pd.concat(oof,axis=0,ignore_index=True).set_index('customer_ID')\n",
    "    amex_metric_mod(oof.target.values, oof.oof_pred.values)\n",
    "    return oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in train.columns if col not in ['customer_ID', 'target','S_2']]\n",
    "features = [col for col in features if 'B_29' not in col]\n",
    "print(f'There are {len(features)} features!')\n",
    "print(train.shape)\n",
    "\n",
    "oof = run_training(train, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Fold Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_xgb = pd.read_pickle(TRAIN_PATH)[['customer_ID']].drop_duplicates()\n",
    "oof_xgb = oof_xgb.set_index('customer_ID')\n",
    "oof_xgb = oof_xgb.merge(oof, left_index=True, right_index=True)\n",
    "oof_xgb = oof_xgb.sort_index().reset_index()\n",
    "oof_xgb.to_csv(f'oof_xgb_v{VER}.csv',index=False)\n",
    "oof_xgb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = importances[0].copy()\n",
    "for k in range(1,FOLDS): df = df.merge(importances[k], on='feature', how='left')\n",
    "df['importance'] = df.iloc[:,1:].mean(axis=1)\n",
    "df = df.sort_values('importance',ascending=False)\n",
    "df.to_csv(f'xgb_feature_importance_v{VER}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 30\n",
    "plt.figure(figsize=(10,5*NUM_FEATURES//10))\n",
    "plt.barh(np.arange(NUM_FEATURES,0,-1), df.importance.values[:NUM_FEATURES])\n",
    "plt.yticks(np.arange(NUM_FEATURES,0,-1), df.feature.values[:NUM_FEATURES])\n",
    "plt.title(f'XGB Feature Importance - Top {NUM_FEATURES}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_SUBMIT = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_SUBMIT:\n",
    "    gc.collect()\n",
    "    TEST_SECTIONS = 1\n",
    "    TEST_SUB_SECTIONS = 1\n",
    "    test_preds = []\n",
    "    customers = False\n",
    "    for k in range(TEST_SECTIONS):\n",
    "        for i in range(TEST_SUB_SECTIONS):    \n",
    "            print(f'\\nReading test data...')\n",
    "            test = cudf.read_pickle(f'test_fe_v1.pickle')\n",
    "            test = do_miss_nan(test)\n",
    "            if i == 0:\n",
    "                print(f'=> Test part {k+1} has shape', test.shape )\n",
    "                if k == 0:\n",
    "                    customers = test.index.copy()\n",
    "                else:\n",
    "                    customers = customers.append(test.index)\n",
    "            X_test = test[features]\n",
    "            n_rows = len(test.index)//TEST_SUB_SECTIONS\n",
    "            print(\".\")\n",
    "            if i+1 < TEST_SUB_SECTIONS:\n",
    "                X_test = X_test.iloc[i*n_rows:(i+1)*n_rows, :].copy()\n",
    "            elif TEST_SUB_SECTIONS > 1:\n",
    "                X_test = X_test.iloc[i*n_rows:, :].copy()\n",
    "            print(f'=> Test piece {k+1}, {i+1} has shape', X_test.shape )\n",
    "            del test\n",
    "            gc.collect()\n",
    "            dtest = xgb.DMatrix(data=X_test)\n",
    "            del X_test\n",
    "            gc.collect()\n",
    "            reset_margin = dtest.get_base_margin()\n",
    "            print(\".\")\n",
    "            for f in range(FOLDS):\n",
    "                if (f > 0):\n",
    "                    dtest.set_base_margin(reset_margin)\n",
    "                for (layer, w) in enumerate(PYRAMID_W[:-1]):\n",
    "                    model = xgb.Booster()\n",
    "                    model.load_model(f'XGB_v{VER}_fold{f}_layer{layer}.xgb')\n",
    "                    print(f'Loaded fold{f}, layer{layer}')\n",
    "                    ptest = model.predict(dtest, output_margin=True)\n",
    "                    if (w < 1.0):\n",
    "                        ptest = ptest * w\n",
    "                    dtest.set_base_margin(ptest)\n",
    "                layer = len(PYRAMID_W) - 1\n",
    "                model = xgb.Booster()\n",
    "                model.load_model(f'XGB_v{VER}_fold{f}_layer{layer}.xgb')\n",
    "                print(\"Best_ntree_limit\", model.best_ntree_limit//xgb_params['num_parallel_tree'])\n",
    "                if f == 0:\n",
    "                    preds = model.predict(dtest, output_margin=False, iteration_range=(0,model.best_ntree_limit//xgb_params['num_parallel_tree']))\n",
    "                else:\n",
    "                    preds += model.predict(dtest, output_margin=False, iteration_range=(0,model.best_ntree_limit//xgb_params['num_parallel_tree']))\n",
    "            preds /= FOLDS\n",
    "            test_preds.append(preds)\n",
    "            del dtest, model, reset_margin\n",
    "            _ = gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_SUBMIT:\n",
    "    test = cudf.DataFrame(index=customers,data={'prediction':test_preds[0]})\n",
    "    sub = cudf.read_csv('../input/amex-default-prediction/sample_submission.csv')[['customer_ID']]\n",
    "    sub = sub.merge(test[['prediction']], left_index=True, right_index=True, how='left')\n",
    "    sub = sub.reset_index(drop=True)\n",
    "\n",
    "    sub.to_csv(f'../sub/submission_xgb.csv',index=False)\n",
    "    print('Submission file shape is', sub.shape )\n",
    "    sub.head()\n",
    "\n",
    "    plt.hist(sub.prediction, bins=100)\n",
    "    plt.title('Test Predictions')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
