{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM (CITEseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --quiet tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/open-problems-multimodal\"\n",
    "FP_CELL_METADATA = os.path.join(DATA_DIR,\"metadata.csv\")\n",
    "\n",
    "#raw training inputs: gene expressions\n",
    "FP_CITE_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_cite_inputs.h5\")\n",
    "#raw training targets: protein levels\n",
    "FP_CITE_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_cite_targets.h5\")\n",
    "#raw test inputs\n",
    "FP_CITE_TEST_INPUTS = os.path.join(DATA_DIR,\"test_cite_inputs.h5\")\n",
    "\n",
    "#raw training inputs: chromatin accessibility\n",
    "FP_MULTIOME_TRAIN_INPUTS = os.path.join(DATA_DIR,\"train_multi_inputs.h5\")\n",
    "#raw training targets: gene expression\n",
    "FP_MULTIOME_TRAIN_TARGETS = os.path.join(DATA_DIR,\"train_multi_targets.h5\")\n",
    "#raw test inputs\n",
    "FP_MULTIOME_TEST_INPUTS = os.path.join(DATA_DIR,\"test_multi_inputs.h5\")\n",
    "\n",
    "#sample submission file\n",
    "FP_SUBMISSION = os.path.join(DATA_DIR,\"sample_submission.csv\")\n",
    "FP_EVALUATION_IDS = os.path.join(DATA_DIR,\"evaluation_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_score(y_true, y_pred):\n",
    "    if type(y_true) == pd.DataFrame: y_true = y_true.values\n",
    "    if type(y_pred) == pd.DataFrame: y_pred = y_pred.values\n",
    "    corrsum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        corrsum += np.corrcoef(y_true[i], y_pred[i])[1, 0]\n",
    "    return corrsum / len(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the raw datametadata.csv file \n",
    "metadata_df = pd.read_csv(FP_CELL_METADATA, index_col='cell_id')\n",
    "metadata_df = metadata_df[metadata_df.technology==\"citeseq\"]\n",
    "metadata_df.shape\n",
    "\n",
    "#generate donor-time labels for the cells\n",
    "conditions = [\n",
    "    metadata_df['donor'].eq(27678) & metadata_df['day'].eq(2),\n",
    "    metadata_df['donor'].eq(27678) & metadata_df['day'].eq(3),\n",
    "    metadata_df['donor'].eq(27678) & metadata_df['day'].eq(4),\n",
    "    metadata_df['donor'].eq(27678) & metadata_df['day'].eq(7),\n",
    "    metadata_df['donor'].eq(13176) & metadata_df['day'].eq(2),\n",
    "    metadata_df['donor'].eq(13176) & metadata_df['day'].eq(3),\n",
    "    metadata_df['donor'].eq(13176) & metadata_df['day'].eq(4),\n",
    "    metadata_df['donor'].eq(13176) & metadata_df['day'].eq(7),\n",
    "    metadata_df['donor'].eq(31800) & metadata_df['day'].eq(2),\n",
    "    metadata_df['donor'].eq(31800) & metadata_df['day'].eq(3),\n",
    "    metadata_df['donor'].eq(31800) & metadata_df['day'].eq(4),\n",
    "    metadata_df['donor'].eq(31800) & metadata_df['day'].eq(7),\n",
    "    metadata_df['donor'].eq(32606) & metadata_df['day'].eq(2),\n",
    "    metadata_df['donor'].eq(32606) & metadata_df['day'].eq(3),\n",
    "    metadata_df['donor'].eq(32606) & metadata_df['day'].eq(4),\n",
    "    metadata_df['donor'].eq(32606) & metadata_df['day'].eq(7)\n",
    "    ]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "metadata_df['comb'] = np.select(conditions, values)\n",
    "\n",
    "#reindex the training data\n",
    "X = pd.read_hdf(FP_CITE_TRAIN_INPUTS)\n",
    "cell_index = X.index\n",
    "meta = metadata_df.reindex(cell_index)\n",
    "del X\n",
    "gc.collect()\n",
    "\n",
    "#import the feature processed training set: 512 truncated SVD dimensions + 364 important columns\n",
    "cite_train_x = pd.read_csv('../result/fe/X_876.csv').values\n",
    "cite_train_y = pd.read_hdf(FP_CITE_TRAIN_TARGETS).values\n",
    "print(cite_train_x.shape)\n",
    "print(cite_train_y.shape)\n",
    "\n",
    "#import the feature processed test set\n",
    "cite_test_x = pd.read_csv('../result/fe/Xt_876.csv').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters of the LightGBM model\n",
    "params = {\n",
    "    'n_estimators': 300, \n",
    "    'learning_rate': 0.1, \n",
    "    'max_depth': 10, \n",
    "    'num_leaves': 200,\n",
    "    'min_child_samples': 250,\n",
    "    'colsample_bytree': 0.8, \n",
    "    'subsample': 0.6, \n",
    "    \"seed\": 1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = 0\n",
    "N_SPLITS_ANN = len(meta['comb'].value_counts())\n",
    "\n",
    "#use GroupKFold to balance the number of distinct donor-time groups in each fold\n",
    "kf = GroupKFold(n_splits=N_SPLITS_ANN)\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(kf.split(cite_train_x, groups=meta.comb)):\n",
    "    \n",
    "    model = None\n",
    "    gc.collect()\n",
    "    \n",
    "    #split the data into training and validation sets\n",
    "    X_train = cite_train_x[idx_tr] \n",
    "    y_train = cite_train_y[idx_tr]\n",
    "    X_val = cite_train_x[idx_va]\n",
    "    y_val = cite_train_y[idx_va]\n",
    "    \n",
    "    #use MultiOutputRegressor on top of LightGBM to cope with multiple outputs\n",
    "    model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n",
    "    \n",
    "    #train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #make predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    #compute the mean-square-error and correlation scores\n",
    "    mse = mean_squared_error(y_val, y_pred)\n",
    "    corrscore = correlation_score(y_val, y_pred)\n",
    "    print(mse, corrscore)\n",
    "\n",
    "    #cumulate (blend) the outputs of the models on the test set as the final predictions\n",
    "    test_pred = test_pred + model.predict(cite_test_x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv( DATA_DIR +'/sample_submission.csv')   \n",
    "submission.loc[:48663*140-1,'target'] = test_pred.reshape(-1)\n",
    "submission.to_csv(f'../result/cite/LGBM_submission.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
